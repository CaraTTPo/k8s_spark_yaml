apiVersion: v1
kind: Pod
metadata:
  labels:
    spark-app-selector: spark-appid-1
    spark-role: driver
  name: spark-appname-1
  namespace: dev
  selfLink: /api/v1/namespaces/dev/pods/spark-appname-1
spec:
  containers:
  - args:
    - driver
    - --properties-file
    - /opt/spark/work-dir/conf/spark.properties
    - --class
    - org.apache.spark.examples.SparkPi
    - spark-internal
    env:
    - name: SPARK_DRIVER_BIND_ADDRESS
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: SPARK_LOCAL_DIRS
      value: /var/data/spark-2befb15a-debe-4f61-b9cc-3811806d9851
    - name: SPARK_CONF_DIR
      value: /opt/spark/conf
    - name: HADOOP_CONF_DIR
      value: /opt/hadoop/conf
    image: registry-vpc.cn-hangzhou.aliyuncs.com/eigenlab/pyspark-gevent-k8s:2.4.3
    imagePullPolicy: Always
    name: spark-kubernetes-driver
    ports:
    - containerPort: 7078
      name: driver-rpc-port
      protocol: TCP
    - containerPort: 7079
      name: blockmanager
      protocol: TCP
    - containerPort: 4040
      name: spark-ui
      protocol: TCP
    resources:
      limits:
        memory: 1408Mi
      requests:
        cpu: "1"
        memory: 1408Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/data/spark-2befb15a-debe-4f61-b9cc-3811806d9851
      name: spark-local-dir-1
    - mountPath: /opt/spark/conf
      name: spark-conf-volume
    - mountPath: /opt/hadoop/conf
      name: hadoop-conf-volume
    - mountPath: /opt/spark/work-dir/conf/
      name: user-conf
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: spark-token-ssbkt
      readOnly: true
  dnsPolicy: ClusterFirst
  imagePullSecrets:
  - name: aliyun-registry
  nodeName: sa3.k8s.aipp.io
  restartPolicy: Never
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: spark
  serviceAccountName: spark
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - emptyDir: {}
    name: spark-local-dir-1
  - configMap:
      defaultMode: 444
      name: eigen-spark-conf
    name: spark-conf-volume
  - configMap:
      defaultMode: 444
      name: eigen-hadoop-conf
    name: hadoop-conf-volume
  - configMap:
      defaultMode: 420
      name: spark-appname-1-conf-map
    name: user-conf
  - name: spark-token-ssbkt
    secret:
      defaultMode: 420
      secretName: spark-token-ssbkt
